{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomcoomer123/mysoginy_meme_detection_hinglish/blob/main/Mysoginy_English_Hindi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yRxRyrtLkH0"
      },
      "source": [
        "1.connecting to google drive\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5pRqoCS_5ig",
        "outputId": "e8f1e594-a496-4cb9-f209-69e9b70a8550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3zoxxbYOQxJ"
      },
      "source": [
        "1.Importing all libraries neede to build the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eexieNAVOPmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d99d9a6-452d-42c7-9ed0-f56ccbf3962b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade transformers\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "import math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, optimizers, losses, metrics\n",
        "from tensorflow.keras.applications import (\n",
        "    VGG19,\n",
        "    ResNet152,\n",
        "    EfficientNetB4\n",
        ")\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    TFAutoModel,\n",
        "    TFAutoModelForSequenceClassification\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    confusion_matrix\n",
        ")\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiTkgs8pQTU3"
      },
      "source": [
        "1.Extracting the dataset and analysing it\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf_LXaI3d0Pn"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbOvEgVLQSwl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "b0112e9c-161e-41ff-f5ac-b874583a893e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileName           0\n",
              "ExtractedText      0\n",
              "Misogyny           0\n",
              "Objectification    0\n",
              "Prejudice          0\n",
              "Humiliation        0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>FileName</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtractedText</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Misogyny</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Objectification</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Prejudice</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Humiliation</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "DATASET_ROOT = DATASET_ROOT = \"/content/drive/MyDrive/Datasets/English_hindi\"\n",
        "csv_path = os.path.join(DATASET_ROOT, \"MIMIC2024.csv\")\n",
        "df = pd.read_csv(csv_path)\n",
        "df['ExtractedText'] = df['ExtractedText'].fillna(\"\")\n",
        "df.isnull().sum()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNswCAQLfNTJ"
      },
      "source": [
        "making the final dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVshs-CdfNA3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "b86029c8-9b94-4451-bcc4-666bd24bda63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Misogyny                                      ExtractedText  \\\n",
              "0         1                    haldi wala doodh turmeric latte   \n",
              "1         1                                  à¥­OKA BOLO QDOUDDO   \n",
              "2         0  Kuch Mahino baad ye bhi Maa ban jayegi! Taimur...   \n",
              "3         1                          Mujhe to kuch aur hi laga   \n",
              "4         0  Teacher tum kal school kyu nhi aaye the Me kyu...   \n",
              "\n",
              "                                          image_path  \n",
              "0  /content/drive/MyDrive/Datasets/English_hindi/...  \n",
              "1  /content/drive/MyDrive/Datasets/English_hindi/...  \n",
              "2  /content/drive/MyDrive/Datasets/English_hindi/...  \n",
              "3  /content/drive/MyDrive/Datasets/English_hindi/...  \n",
              "4  /content/drive/MyDrive/Datasets/English_hindi/...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d070d825-49d1-448c-902b-f78443c86fed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Misogyny</th>\n",
              "      <th>ExtractedText</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>haldi wala doodh turmeric latte</td>\n",
              "      <td>/content/drive/MyDrive/Datasets/English_hindi/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>à¥­OKA BOLO QDOUDDO</td>\n",
              "      <td>/content/drive/MyDrive/Datasets/English_hindi/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Kuch Mahino baad ye bhi Maa ban jayegi! Taimur...</td>\n",
              "      <td>/content/drive/MyDrive/Datasets/English_hindi/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Mujhe to kuch aur hi laga</td>\n",
              "      <td>/content/drive/MyDrive/Datasets/English_hindi/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Teacher tum kal school kyu nhi aaye the Me kyu...</td>\n",
              "      <td>/content/drive/MyDrive/Datasets/English_hindi/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d070d825-49d1-448c-902b-f78443c86fed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d070d825-49d1-448c-902b-f78443c86fed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d070d825-49d1-448c-902b-f78443c86fed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_final",
              "summary": "{\n  \"name\": \"df_final\",\n  \"rows\": 5054,\n  \"fields\": [\n    {\n      \"column\": \"Misogyny\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ExtractedText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4888,\n        \"samples\": [\n          \"\\u0915\\u093e\\u091c\\u0942 \\u0915\\u093f\\u0924\\u0928\\u0947 \\u092d\\u0940 \\u0938\\u094d\\u0935\\u093e\\u0926\\u093f\\u0937\\u094d\\u091f \\u0915\\u094d\\u092f\\u094b\\u0902 \\u0928\\u093e \\u0939\\u094b\\u0902 , \\u0935\\u094b \\u092a\\u094b\\u0939\\u0947 \\u092e\\u0947\\u0902 \\u092e\\u0942\\u0902\\u0917\\u092b\\u0932\\u0940 \\u0915\\u0940 \\u091c\\u0917\\u0939 \\u0928\\u0939\\u0940\\u0902 \\u0932\\u0947 \\u0938\\u0915\\u0924\\u0947 , \\u0907\\u0938\\u0940 \\u092a\\u094d\\u0930\\u0915\\u093e\\u0930 \\u092a\\u0921\\u094b\\u0938\\u0928 \\u092d\\u0940 \\u0915\\u093f\\u0924\\u0928\\u0940 \\u092d\\u0940 \\u0938\\u0941\\u0902\\u0926\\u0930 \\u0939\\u094b, \\u0935\\u094b \\u092a\\u0924\\u094d\\u0928\\u0940 \\u0915\\u0940 \\u091c\\u0917\\u0939 \\u0915\\u092d\\u0940 \\u0928\\u0939\\u0940 \\u0932\\u0947 \\u0938\\u0915\\u0924\\u0940|\",\n          \"\\u092b\\u0942\\u0932\\u0914\\u0930 \\u0924\\u093f\\u0924\\u0932\\u0940 \\u092e\\u0947\\u0902 \\u0930\\u093f\\u0936\\u094d\\u0924\\u093e \\u0939\\u094d\\u0930\\u094b \\u0939\\u0940 \\u091c\\u093e\\u0924\\u093e \\u0939\\u0948\\u0970\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5054,\n        \"samples\": [\n          \"/content/drive/MyDrive/Datasets/English_hindi/Files/445_M_pic_1.jpg\",\n          \"/content/drive/MyDrive/Datasets/English_hindi/Files/1562_NM_pic.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "target_col = \"Misogyny\"\n",
        "text_col = \"ExtractedText\"\n",
        "df['image_path'] = df['FileName'].apply(\n",
        "    lambda x: os.path.join(DATASET_ROOT, \"Files\", x)\n",
        ")\n",
        "df_final = pd.concat([df[target_col],df[text_col],df['image_path']],axis = 1)\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvnvSZOkv87v"
      },
      "source": [
        "Train test and split\n",
        "\n",
        "1.   Training Data - 70%\n",
        "2.   Testing data - 15%\n",
        "3.   validation data - 15%\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVEEVdJcwNJ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ab3ca9-3a89-4fdd-9f70-67e43226a818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3537 758 759\n"
          ]
        }
      ],
      "source": [
        "train_df, temp_df = train_test_split(\n",
        "    df_final,\n",
        "    test_size=0.3,\n",
        "    stratify=df_final[target_col],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    stratify=temp_df[target_col],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(len(train_df), len(val_df), len(test_df))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R60foZtQwb08"
      },
      "source": [
        "Checking imbalance in data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2PYeYpGwafz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f1d011-98a8-44d4-bb0a-33107c45dd9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.009659090909091"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "class_count = train_df[target_col].value_counts()\n",
        "class_count\n",
        "\n",
        "imbalance_ratio = class_count.max() / class_count.min()\n",
        "imbalance_ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUXFvvTMyfui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b4ea43-ffc9-4f46-c41c-097a991a085f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Relax guys Coke pi rhi h bechari',\n",
              " np.int64(1),\n",
              " 'Girl With 8M followers BoyWith à¥¨à¥¦OM follà¥­wess',\n",
              " np.int64(1),\n",
              " 'à¤¶à¤°à¤¾à¤«à¤¤ à¤•à¥€ à¤•à¤¿à¤¸à¥à¤¸à¤¾ à¤–à¤¤à¥à¤® à¤…à¤¬ à¤œà¥ˆà¤¸à¥€ à¤µà¥ˆà¤¸à¥‡ à¤¹à¤® à¤¦à¥à¤¨à¤¿à¤¯à¤¾ à¤Ÿà¥à¤¨à¤¿à¤¯à¤¾',\n",
              " np.int64(0)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "X_train_text = train_df[text_col].astype(str).tolist()\n",
        "X_val_text   = val_df[text_col].astype(str).tolist()\n",
        "X_test_text  = test_df[text_col].astype(str).tolist()\n",
        "\n",
        "y_train = train_df[target_col].astype(int).values\n",
        "y_val   = val_df[target_col].astype(int).values\n",
        "y_test  = test_df[target_col].astype(int).values\n",
        "[X_train_text[0], y_train[0],X_val_text[0], y_val[0],X_test_text[0], y_test[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUNpFISQwo56"
      },
      "outputs": [],
      "source": [
        "@tf.keras.utils.register_keras_serializable()\n",
        "class HFBackbone(tf.keras.layers.Layer):\n",
        "    def __init__(self, model_name, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.model_name = model_name\n",
        "        self.transformer = TFAutoModel.from_pretrained(model_name, use_safetensors=False)\n",
        "\n",
        "        # Fine-tune only last 2 layers\n",
        "        for layer in self.transformer.layers[:-2]:\n",
        "            layer.trainable = False\n",
        "        for layer in self.transformer.layers[-2:]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids, attention_mask = inputs\n",
        "        return self.transformer(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            training=True\n",
        "        ).last_hidden_state\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"model_name\": self.model_name})\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QdnJYi0wxFh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# ------------------ Pooling ------------------\n",
        "\n",
        "class MeanMaxPooling(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        outputs, attention_mask = inputs\n",
        "        mask = tf.cast(tf.expand_dims(attention_mask, -1), tf.float32)\n",
        "        masked = outputs * mask\n",
        "\n",
        "        mean_pool = tf.reduce_sum(masked, axis=1) / tf.reduce_sum(mask, axis=1)\n",
        "        max_pool = tf.reduce_max(masked, axis=1)\n",
        "\n",
        "        return tf.concat([mean_pool, max_pool], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "# ------------------ Evaluation ------------------\n",
        "\n",
        "def evaluate_predictions(y_true, probs):\n",
        "    preds = (probs > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_true, preds)\n",
        "    f1  = f1_score(y_true, preds, average=\"macro\")\n",
        "    return acc, f1\n",
        "\n",
        "# ------------------ Training Function ------------------\n",
        "def train_evaluate_text_model(\n",
        "    model_name,\n",
        "    X_train, y_train,\n",
        "    X_val, y_val,\n",
        "    X_test, y_test,\n",
        "    epochs=30,          # ğŸ”¥ allow long training\n",
        "    batch_size=16,\n",
        "    max_len=128\n",
        "):\n",
        "\n",
        "\n",
        "    print(f\"\\nğŸš€ Training TEXT model: {model_name}\\n\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    def tokenize(texts):\n",
        "        return tokenizer(\n",
        "            list(texts),\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=max_len,\n",
        "            return_tensors=\"tf\"\n",
        "        )\n",
        "\n",
        "    train_enc = tokenize(X_train)\n",
        "    val_enc   = tokenize(X_val)\n",
        "    test_enc  = tokenize(X_test)\n",
        "\n",
        "    # ------------------ Backbone ------------------\n",
        "\n",
        "    transformer = TFAutoModel.from_pretrained(\n",
        "        model_name,\n",
        "        use_safetensors=False\n",
        "    )\n",
        "\n",
        "    # ğŸ”¥ Fine-tune only last 2 layers (safe + powerful)\n",
        "    for layer in transformer.layers[:-2]:\n",
        "        layer.trainable = False\n",
        "    for layer in transformer.layers[-2:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    # ------------------ Model ------------------\n",
        "\n",
        "    input_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "    attention_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "    sequence_output = HFBackbone(model_name)([input_ids, attention_mask])\n",
        "\n",
        "\n",
        "    pooled = MeanMaxPooling()([sequence_output, attention_mask])\n",
        "\n",
        "    # ğŸ”¹ Simple classifier head\n",
        "\n",
        "    x = tf.keras.layers.Dense(256,activation=\"relu\")(pooled)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(128,activation=\"relu\")(x)   # or use 64 here\n",
        "\n",
        "\n",
        "\n",
        "    logits = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[input_ids, attention_mask],\n",
        "        outputs=logits\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),   # ğŸ”¥ slower & better\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    # ------------------ Early Stopping ------------------\n",
        "\n",
        "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=4,             # stop if no improvement for 4 epochs\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    # ------------------ Training ------------------\n",
        "\n",
        "    history = model.fit(\n",
        "        {\n",
        "            \"input_ids\": train_enc[\"input_ids\"],\n",
        "            \"attention_mask\": train_enc[\"attention_mask\"]\n",
        "        },\n",
        "        y_train,\n",
        "        validation_data=(\n",
        "            {\n",
        "                \"input_ids\": val_enc[\"input_ids\"],\n",
        "                \"attention_mask\": val_enc[\"attention_mask\"]\n",
        "            },\n",
        "            y_val\n",
        "        ),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # ğŸ”¹ Ensure minimum 10 epochs\n",
        "    trained_epochs = len(history.history[\"loss\"])\n",
        "    print(f\"\\nğŸ§  Trained for {trained_epochs} epochs\")\n",
        "\n",
        "    # ------------------ Testing ------------------\n",
        "\n",
        "    logits = model.predict(\n",
        "        {\n",
        "            \"input_ids\": test_enc[\"input_ids\"],\n",
        "            \"attention_mask\": test_enc[\"attention_mask\"]\n",
        "        },\n",
        "        batch_size=batch_size\n",
        "    ).squeeze()\n",
        "\n",
        "    probs = tf.nn.sigmoid(logits).numpy()\n",
        "\n",
        "    acc, f1 = evaluate_predictions(y_test, probs)\n",
        "\n",
        "    print(\"\\nâœ… Final Test Results\")\n",
        "    print(f\"Accuracy : {acc:.4f}\")\n",
        "    print(f\"Macro F1 : {f1:.4f}\")\n",
        "\n",
        "    return model,acc, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hs-oGElVw1aU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6dffc95-977c-4c3e-f106-e8481605b169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating TEXT model: roberta-base\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
            "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 192ms/step - accuracy: 0.5173 - loss: 0.6940 - val_accuracy: 0.5172 - val_loss: 0.6829\n",
            "Epoch 2/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 128ms/step - accuracy: 0.5128 - loss: 0.6822 - val_accuracy: 0.5211 - val_loss: 0.6788\n",
            "Epoch 3/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 124ms/step - accuracy: 0.5177 - loss: 0.6768 - val_accuracy: 0.5330 - val_loss: 0.6753\n",
            "Epoch 4/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 128ms/step - accuracy: 0.5254 - loss: 0.6717 - val_accuracy: 0.5343 - val_loss: 0.6719\n",
            "Epoch 5/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 125ms/step - accuracy: 0.5368 - loss: 0.6700 - val_accuracy: 0.5435 - val_loss: 0.6694\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 469ms/step\n",
            "\n",
            "Evaluating TEXT model: google-bert/bert-base-uncased\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at google-bert/bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at google-bert/bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 192ms/step - accuracy: 0.5090 - loss: 0.6927 - val_accuracy: 0.5198 - val_loss: 0.6839\n",
            "Epoch 2/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 139ms/step - accuracy: 0.5104 - loss: 0.6827 - val_accuracy: 0.5172 - val_loss: 0.6764\n",
            "Epoch 3/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 137ms/step - accuracy: 0.5250 - loss: 0.6724 - val_accuracy: 0.5158 - val_loss: 0.6715\n",
            "Epoch 4/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 137ms/step - accuracy: 0.5317 - loss: 0.6662 - val_accuracy: 0.5317 - val_loss: 0.6694\n",
            "Epoch 5/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 138ms/step - accuracy: 0.5450 - loss: 0.6646 - val_accuracy: 0.5396 - val_loss: 0.6665\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 466ms/step\n",
            "\n",
            "Evaluating TEXT model: albert-base-v2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at albert-base-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-base-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 188ms/step - accuracy: 0.5163 - loss: 0.7307 - val_accuracy: 0.5158 - val_loss: 0.6897\n",
            "Epoch 2/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.5161 - loss: 0.6880 - val_accuracy: 0.5303 - val_loss: 0.6817\n",
            "Epoch 3/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 134ms/step - accuracy: 0.5244 - loss: 0.6720 - val_accuracy: 0.5369 - val_loss: 0.6748\n",
            "Epoch 4/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 134ms/step - accuracy: 0.5335 - loss: 0.6703 - val_accuracy: 0.5290 - val_loss: 0.6700\n",
            "Epoch 5/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 135ms/step - accuracy: 0.5356 - loss: 0.6581 - val_accuracy: 0.5290 - val_loss: 0.6643\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 447ms/step\n",
            "\n",
            "Evaluating TEXT model: google/muril-base-cased\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at google/muril-base-cased were not used when initializing TFBertModel: ['mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFBertModel were not initialized from the model checkpoint at google/muril-base-cased and are newly initialized: ['bert/pooler/dense/bias:0', 'bert/pooler/dense/kernel:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 200ms/step - accuracy: 0.5128 - loss: 0.6929 - val_accuracy: 0.5026 - val_loss: 0.6930\n",
            "Epoch 2/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 138ms/step - accuracy: 0.4997 - loss: 0.6930 - val_accuracy: 0.5026 - val_loss: 0.6928\n",
            "Epoch 3/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.4837 - loss: 0.6930 - val_accuracy: 0.5026 - val_loss: 0.6926\n",
            "Epoch 4/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.5004 - loss: 0.6926 - val_accuracy: 0.5026 - val_loss: 0.6924\n",
            "Epoch 5/5\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 137ms/step - accuracy: 0.5053 - loss: 0.6923 - val_accuracy: 0.5026 - val_loss: 0.6922\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 432ms/step\n"
          ]
        }
      ],
      "source": [
        "text_models = [\n",
        "    \"roberta-base\",\n",
        "    \"google-bert/bert-base-uncased\",\n",
        "    \"albert-base-v2\",\n",
        "    \"google/muril-base-cased\",\n",
        "    ]\n",
        "\n",
        "results = []\n",
        "\n",
        "for model_name in text_models:\n",
        "    print(f\"\\nEvaluating TEXT model: {model_name}\")\n",
        "    acc, f1 = train_evaluate_text_model(\n",
        "            model_name,\n",
        "            X_train_text, y_train,\n",
        "            X_val_text, y_val,\n",
        "            X_test_text, y_test,\n",
        "            epochs=5,\n",
        "            batch_size=16\n",
        "        )\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Macro_F1\": f1\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuXBugZHw3mG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "9492e371-0083-444d-ec9d-71cf114fa253"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           Model  Accuracy  Macro_F1\n",
              "0                   roberta-base  0.591568  0.589715\n",
              "2                 albert-base-v2  0.581028  0.577329\n",
              "1  google-bert/bert-base-uncased  0.575758  0.575137\n",
              "3        google/muril-base-cased  0.527009  0.459639"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a886b43b-e196-4af0-847e-2ca75956f4ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Macro_F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>roberta-base</td>\n",
              "      <td>0.591568</td>\n",
              "      <td>0.589715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>albert-base-v2</td>\n",
              "      <td>0.581028</td>\n",
              "      <td>0.577329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>google-bert/bert-base-uncased</td>\n",
              "      <td>0.575758</td>\n",
              "      <td>0.575137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>google/muril-base-cased</td>\n",
              "      <td>0.527009</td>\n",
              "      <td>0.459639</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a886b43b-e196-4af0-847e-2ca75956f4ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a886b43b-e196-4af0-847e-2ca75956f4ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a886b43b-e196-4af0-847e-2ca75956f4ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"text_results_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"albert-base-v2\",\n          \"google/muril-base-cased\",\n          \"roberta-base\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.028651709158322086,\n        \"min\": 0.5270092226613966,\n        \"max\": 0.5915678524374176,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5810276679841897,\n          0.5270092226613966,\n          0.5915678524374176\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Macro_F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06088356797809763,\n        \"min\": 0.45963863664758253,\n        \"max\": 0.5897154216363256,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5773290837769683,\n          0.45963863664758253,\n          0.5897154216363256\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "text_results_df = pd.DataFrame(results)\n",
        "text_results_df.sort_values(by=\"Macro_F1\", ascending=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image unimodal testing\n"
      ],
      "metadata": {
        "id": "hThBPxV9HVHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_img = train_df[\"image_path\"].values   # full path to image\n",
        "X_val_img   = val_df[\"image_path\"].values\n",
        "X_test_img  = test_df[\"image_path\"].values\n",
        "\n",
        "y_train = train_df[\"Misogyny\"].values\n",
        "y_val   = val_df[\"Misogyny\"].values\n",
        "y_test  = test_df[\"Misogyny\"].values\n"
      ],
      "metadata": {
        "id": "ttch9xETHjZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_predictions(y_true, probs, threshold=0.5):\n",
        "    y_pred = (probs >= threshold).astype(int)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    return acc, f1\n"
      ],
      "metadata": {
        "id": "Chqs0hpRM-Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "\n",
        "def load_image(path, label):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img, label\n",
        "\n",
        "\n",
        "def make_dataset(X, y, batch_size=32, shuffle=False):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "    ds = ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(1000)\n",
        "\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n"
      ],
      "metadata": {
        "id": "5qhWZwc_M--F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate_image_model(\n",
        "    model_name,\n",
        "    base_model_fn,\n",
        "    X_train, y_train,\n",
        "    X_val, y_val,\n",
        "    X_test, y_test,\n",
        "    img_size=224,\n",
        "    epochs=5,\n",
        "    batch_size=32\n",
        "):\n",
        "\n",
        "    # Datasets\n",
        "    train_ds = make_dataset(X_train, y_train, batch_size, shuffle=True)\n",
        "    val_ds   = make_dataset(X_val, y_val, batch_size)\n",
        "    test_ds  = make_dataset(X_test, y_test, batch_size)\n",
        "\n",
        "    # Base model\n",
        "    base_model = base_model_fn(\n",
        "        input_shape=(img_size, img_size, 3),\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\"\n",
        "    )\n",
        "    base_model.trainable = False   # ğŸ”¥ freeze backbone\n",
        "\n",
        "    # Model head\n",
        "    inputs = tf.keras.Input(shape=(img_size, img_size, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    if len(x.shape) == 4:\n",
        "      x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(0.4)(x)\n",
        "    logits = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, logits)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(2e-4),\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=epochs,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Test\n",
        "    logits = model.predict(test_ds).ravel()\n",
        "    probs = tf.sigmoid(logits).numpy()\n",
        "\n",
        "    acc, f1 = evaluate_predictions(y_test, probs)\n",
        "\n",
        "    return model,acc, f1\n"
      ],
      "metadata": {
        "id": "KBuEfAQdNBk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications import EfficientNetV2B0\n",
        "\n",
        "\n",
        "# -------- Vision Transformer (VALID TF-HUB) --------\n",
        "def vit_model_fn(input_shape, include_top=False, weights=None):\n",
        "    vit_layer = hub.KerasLayer(\n",
        "        \"https://tfhub.dev/sayakpaul/vit_s16_fe/1\",\n",
        "        trainable=False\n",
        "    )\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    x = tf.keras.layers.Lambda(\n",
        "        lambda t: vit_layer(t, training=False)\n",
        "    )(inputs)\n",
        "\n",
        "    # Output: (batch, 384)\n",
        "    return tf.keras.Model(inputs, x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -------- BiT Model (VALID) --------\n",
        "def bit_model_fn(input_shape, include_top=False, weights=None):\n",
        "    bit_layer = hub.KerasLayer(\n",
        "        \"https://tfhub.dev/google/bit/m-r50x1/1\",\n",
        "        trainable=False\n",
        "    )\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    x = tf.keras.layers.Lambda(\n",
        "        lambda t: bit_layer(t, training=False)\n",
        "    )(inputs)\n",
        "\n",
        "    # Output: (batch, 384)\n",
        "    return tf.keras.Model(inputs, x)\n"
      ],
      "metadata": {
        "id": "1MfMaWBsNL2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_models = [\n",
        "    #(\"BiT\", bit_model_fn),\n",
        "    #(\"ViT\", vit_model_fn),\n",
        "    #(\"InceptionV3\", InceptionV3),\n",
        "    (\"EfficientNetV2\", EfficientNetV2B0)\n",
        "]\n",
        "\n",
        "image_results = []\n",
        "\n",
        "for name, model_fn in image_models:\n",
        "    print(f\"\\nEvaluating IMAGE model: {name}\")\n",
        "\n",
        "    model,acc, f1 = train_evaluate_image_model(\n",
        "        name,\n",
        "        model_fn,\n",
        "        X_train_img, y_train,\n",
        "        X_val_img, y_val,\n",
        "        X_test_img, y_test,\n",
        "        epochs=5,\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    image_results.append({\n",
        "        \"model_attr\":model,\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Macro_F1\": f1\n",
        "    })\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtcJQdUlNre6",
        "outputId": "f479ebaf-63bb-468e-8158-9faffe91e46c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating IMAGE model: EfficientNetV2\n",
            "Epoch 1/5\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m788s\u001b[0m 6s/step - accuracy: 0.4980 - loss: 0.7046 - val_accuracy: 0.5026 - val_loss: 0.6957\n",
            "Epoch 2/5\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 198ms/step - accuracy: 0.5074 - loss: 0.7023 - val_accuracy: 0.5026 - val_loss: 0.6937\n",
            "Epoch 3/5\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 194ms/step - accuracy: 0.4948 - loss: 0.6977 - val_accuracy: 0.5026 - val_loss: 0.6934\n",
            "Epoch 4/5\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 195ms/step - accuracy: 0.5036 - loss: 0.6950 - val_accuracy: 0.5026 - val_loss: 0.6950\n",
            "Epoch 5/5\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 196ms/step - accuracy: 0.4982 - loss: 0.6957 - val_accuracy: 0.5026 - val_loss: 0.6934\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 6s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_results_df = pd.DataFrame(image_results)\n",
        "print(image_results_df)\n"
      ],
      "metadata": {
        "id": "2rEZIrv-Nssf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b8a9df-dcaf-4462-8e36-1cbcc1ee7d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 model_attr           Model  Accuracy  \\\n",
            "0  <Functional name=functional, built=True>  EfficientNetV2  0.501976   \n",
            "\n",
            "   Macro_F1  \n",
            "0  0.334211  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#image_results[0]['model_attr'].save('model_eff.h5')\n",
        "model_err = tf.keras.models.load_model('/content/model_eff.h5',compile=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7xOe1Vp4neV",
        "outputId": "1f3dce8e-1d57-479d-a6e9-d0b932162bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "8dEV5-fZ5k2e",
        "outputId": "32cb4eb2-505a-4388-e527-71297a29bbbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ efficientnetv2-b0 (\u001b[38;5;33mFunctional\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     â”‚     \u001b[38;5;34m5,919,312\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2d        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚       \u001b[38;5;34m327,936\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m257\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ efficientnetv2-b0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,919,312</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2d        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,247,507\u001b[0m (23.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,247,507</span> (23.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m328,193\u001b[0m (1.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">328,193</span> (1.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,919,312\u001b[0m (22.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,919,312</span> (22.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}